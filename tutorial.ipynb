{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTaaS Tutorial\n",
    "\n",
    "OPTaaS is an optimization service developed by Mind Foundry. It can be used to optimize any function you wish to use; all it needs to know is the parameter space over which the function operates.\n",
    "\n",
    "The procedure is simple: you create a task, which is the definition of the parameters of the function, and send it to OPTaaS. The service will then suggest a configuration (set of values for your parameters) to evaluate. You evaluate the configuration locally and send the score you obtained back to OPTaaS. You then repeat the process until you're happy that the score is good, or that there hasn't been enough progress in a while. \n",
    "\n",
    "Here we demonstrate how to use OPTaaS to optimize a scikit-learn classification pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your dataset\n",
    "\n",
    "Let's load a classic data set, \"iris\", which comes packaged in scikit-learn. The dataset contains three types of flowers, and 50 measurements of four characteristics of these flowers (sepal length, sepal width, petal length and petal width). So we have 150 rows (50 per flower type), 4 input columns (the four features), and one target column (the name of the flower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your pipeline\n",
    "\n",
    "We can then assemble a simple pipeline: we reduce the input dimensions with PCA, and then discover the type of flower with a Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "          ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([('pca', PCA()), ('rf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameters to be optimized\n",
    "\n",
    "Let's now define the parameters for our task. A list of available parameter types can be found [here](autogen/mindfoundry.optaas.client.html#module-mindfoundry.optaas.client.parameter).\n",
    "\n",
    "We can use *constraints* to make sure that the parameter values are always valid, e.g. that `max_features` in our classifier will never be larger than `n_components` in PCA. (see also: [Constraints](constraints.ipynb))\n",
    "\n",
    "scikit-learn pipelines follow a naming convention, so we abide to that convention here. This allows us to plug them in directly into `Pipeline.set_params()`.\n",
    "\n",
    "Note that you don't have to define every single parameter of your pipelines, just the ones you would like to optimize. If you don't know what parameters will lead to better results, give them all to OPTaaS and let it do the hard work for you. However, the more parameters you have, the harder it is to optimize over them, so you will need more iterations to achieve comparable results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '2381133733056', 'name': 'pca__n_components', 'type': 'integer', 'minimum': 1, 'maximum': 4},\n",
       " {'id': '2381133733112', 'name': 'pca__whiten', 'type': 'boolean', 'default': False},\n",
       " {'id': '2381133726832', 'name': 'rf__n_estimators', 'type': 'integer', 'default': 10, 'minimum': 10, 'maximum': 1000, 'distribution': 'LogUniform'},\n",
       " {'id': '2381133728288', 'name': 'rf__criterion', 'type': 'categorical', 'default': 'gini', 'enum': ['gini', 'entropy']},\n",
       " {'id': '2381133728344', 'name': 'rf__max_features', 'type': 'number', 'optional': True, 'minimum': 0.0, 'maximum': 1.0},\n",
       " {'id': '2381133728400', 'name': 'rf__max_depth', 'type': 'integer', 'optional': True, 'default': 1, 'minimum': 1, 'maximum': 100},\n",
       " {'id': '2381133728456', 'name': 'rf__min_samples_split', 'type': 'integer', 'minimum': 2, 'maximum': 20},\n",
       " {'id': '2381133728512', 'name': 'rf__min_samples_leaf', 'type': 'integer', 'minimum': 1, 'maximum': 20}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindfoundry.optaas.client.parameter import IntParameter, BoolParameter, CategoricalParameter, Distribution\n",
    "from mindfoundry.optaas.client.constraint import Constraint\n",
    "\n",
    "feature_count = len(iris.feature_names)\n",
    "n_components = IntParameter('pca__n_components', minimum=1, maximum=feature_count, default=feature_count)\n",
    "max_features = IntParameter('rf__max_features', minimum=1, maximum=feature_count, optional=True)\n",
    "constraint = Constraint(when=max_features.is_present(), then=max_features < n_components) \n",
    "\n",
    "parameters = [\n",
    "    # PCA parameters\n",
    "    n_components,\n",
    "    BoolParameter('pca__whiten', default=False),\n",
    "    \n",
    "    # Random Forest parameters\n",
    "    max_features,\n",
    "    IntParameter('rf__n_estimators', minimum=10, maximum=1000, default=10, distribution=Distribution.LOGUNIFORM),\n",
    "    CategoricalParameter('rf__criterion', values=['gini', 'entropy'], default='gini'),\n",
    "    IntParameter('rf__max_depth', minimum=1, maximum=100, optional=True, default=1),\n",
    "    IntParameter('rf__min_samples_split', minimum=2, maximum=20),\n",
    "    IntParameter('rf__min_samples_leaf', minimum=1, maximum=20),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the OPTaaS server using your API Key\n",
    "\n",
    "We now create a client, and connect to the web service that will perform our optimization. You will need to input your personal API key. Make sure you keep your key private and don't commit it to your version control system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindfoundry.optaas.client.client import OPTaaSClient\n",
    "\n",
    "client = OPTaaSClient('<URL of your OPTaaS server>', '<Your OPTaaS API key>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = client.create_task(\n",
    "    title='My Pipeline Optimization', \n",
    "    parameters=parameters,\n",
    "    constraints=[constraint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the first configuration\n",
    "\n",
    "Here OPTaaS gives us the first configuration (set of parameter values) for our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'id': '327e3b4c-87ea-4790-b268-f4d185df87ee',\n",
       "  'type': 'default',\n",
       "  'values': { 'pca__n_components': 3,\n",
       "              'pca__whiten': False,\n",
       "              'rf__criterion': 'gini',\n",
       "              'rf__max_depth': 1,\n",
       "              'rf__max_features': 2,\n",
       "              'rf__min_samples_leaf': 10,\n",
       "              'rf__min_samples_split': 11,\n",
       "              'rf__n_estimators': 10}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = task.generate_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the configuration to set pipeline parameters and calculate the result\n",
    "\n",
    "We can plug this configuration into our pipeline, run it and score it. We wrapped this into a function so that we can call it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7058823529411765, 0.7647058823529412, 0.6666666666666666],\n",
       " 0.7124183006535948)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def get_result(configuration):\n",
    "    pipeline.set_params(**configuration.values)\n",
    "    scores = cross_val_score(pipeline, iris.data, iris.target, scoring='f1_micro')\n",
    "    mean_score = scores.mean()\n",
    "    return list(scores), mean_score\n",
    "\n",
    "scores, mean_score = get_result(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record the result in OPTaaS and generate the next configuration to try\n",
    "\n",
    "The score we obtained must now be passed back to OPTaaS, which will use it to generate and return a new configuration.\n",
    "\n",
    "You can store additional user-defined data along with your result, but that's entirely optional and for your convenience only. For example, you can store the individual scores for each category so you can easily reference them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ 'id': '1f8287b1-82b4-49da-8888-c0e614b0ce8a',\n",
       "  'type': 'exploration',\n",
       "  'values': { 'pca__n_components': 1,\n",
       "              'pca__whiten': True,\n",
       "              'rf__criterion': 'gini',\n",
       "              'rf__max_depth': 69,\n",
       "              'rf__min_samples_leaf': 13,\n",
       "              'rf__min_samples_split': 10,\n",
       "              'rf__n_estimators': 46}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = task.record_result(configuration, score=mean_score, user_defined_data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat as necessary\n",
    "\n",
    "Repeat the process until you're happy with the result or you've run out of time. How many times should we run it? There is no single answer to this question, but you can look for a certain amount of improvement at each iteration, and stop when you haven't improved in a while. Again this is up to you, and depending on how long you are prepared to wait and perhaps even on how much it costs to run each evaluation on your hardware, especially if you're using a cloud computing service. The more the better (remembering that harder problems, i.e. problems with more parameters, will need more iterations to find a decent solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(number_of_iterations):\n",
    "    scores, mean_score = get_result(configuration)\n",
    "    configuration = task.record_result(configuration, score=mean_score, user_defined_data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete your task\n",
    "\n",
    "Tell OPTaaS that you're satisfied and you won't run any more experiments, then go ahead and get your final result out. Job done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: 0.9403594771241831  [0.9411764705882353, 0.9215686274509803, 0.9583333333333334]\n",
      "Best configuration: { 'id': 'a0caee4e-1ffa-4793-8dff-a59642009936',\n",
      "  'type': 'exploration',\n",
      "  'values': { 'pca__n_components': 2,\n",
      "              'pca__whiten': False,\n",
      "              'rf__criterion': 'entropy',\n",
      "              'rf__min_samples_leaf': 2,\n",
      "              'rf__min_samples_split': 13,\n",
      "              'rf__n_estimators': 987}}\n"
     ]
    }
   ],
   "source": [
    "task.complete()\n",
    "\n",
    "best_result, best_configuration = task.get_best_result_and_configuration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6.0,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
